# Red-Team-LLMs
Example code demonstrating how LLMs could be Red Teamed.
First introduced by [Perez et al., 2022](https://arxiv.org/pdf/2202.03286.pdf), Red Teaming is an approach that could essentially be used to evaluate the alignment of LLMs.

Specifically, this implementation is based off of [Korbak et al., 2023](https://arxiv.org/pdf/2302.08582.pdf).
 
