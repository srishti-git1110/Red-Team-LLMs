# Red-Team-LLMs
Example code demonstrating how LLMs could be Red Teamed.
First introduced by (Perez et al., 2022)[https://arxiv.org/pdf/2202.03286.pdf], Red Teaming is an approach that could essentially be used to evaluate the alignment of LLMs.

I wrote this code as a part of one of my contributions to an Eleuther AI project which will be announced soon.
Specifically, this implementation is based off of (Korbak et al., 2023)[https://arxiv.org/pdf/2302.08582.pdf].
